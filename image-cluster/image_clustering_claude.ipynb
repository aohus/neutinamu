{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aohus/.pyenv/versions/local-venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL.ExifTags import TAGS\n",
    "from datetime import datetime\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, AutoModel, AutoFeatureExtractor\n",
    "import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# 사람 감지를 위한 모델 추가\n",
    "try:\n",
    "    from transformers import DetrImageProcessor, DetrForObjectDetection\n",
    "except ImportError:\n",
    "    print(\"DETR 모델을 위한 transformers 라이브러리가 필요합니다.\")\n",
    "\n",
    "# 고정된 입력 및 출력 디렉토리 설정\n",
    "IMAGE_DIR = \"./1차\"\n",
    "OUTPUT_DIR = IMAGE_DIR + \"_claude\"\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"이미지 모델용 데이터셋 클래스\"\"\"\n",
    "    def __init__(self, image_paths, transform=None, remove_people=False, people_detector=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.remove_people = remove_people\n",
    "        self.people_detector = people_detector\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        try:\n",
    "            # PIL로 이미지 읽기\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # 사람 제거 옵션이 활성화된 경우\n",
    "            if self.remove_people and self.people_detector is not None:\n",
    "                image = self.mask_people(image)\n",
    "            \n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return {\n",
    "                'path': image_path,\n",
    "                'image': image\n",
    "            }\n",
    "        except Exception as e:\n",
    "            print(f\"이미지 {image_path} 로딩 중 오류: {e}\")\n",
    "            # 오류 발생 시 검은색 더미 이미지 반환\n",
    "            dummy = Image.new('RGB', (224, 224), color='black')\n",
    "            if self.transform:\n",
    "                dummy = self.transform(dummy)\n",
    "            return {\n",
    "                'path': image_path,\n",
    "                'image': dummy,\n",
    "                'error': True\n",
    "            }\n",
    "    \n",
    "    def mask_people(self, image):\n",
    "        \"\"\"이미지에서 사람을 감지하고 마스킹\"\"\"\n",
    "        try:\n",
    "            # DETR 모델을 사용하여 사람 감지\n",
    "            inputs = self.people_detector(images=image, return_tensors=\"pt\")\n",
    "            outputs = self.people_detector.model(**inputs)\n",
    "            \n",
    "            # DETR 모델 결과 처리\n",
    "            target_sizes = torch.tensor([image.size[::-1]])\n",
    "            results = self.people_detector.post_process_object_detection(\n",
    "                outputs, target_sizes=target_sizes, threshold=0.7\n",
    "            )[0]\n",
    "            \n",
    "            # NumPy 배열로 변환\n",
    "            img_np = np.array(image)\n",
    "            \n",
    "            # 사람으로 감지된 영역 마스킹 (평균 색상 또는 가우시안 블러로 대체)\n",
    "            for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n",
    "                if label == 1:  # COCO 데이터셋에서 '사람' 클래스는 인덱스 1\n",
    "                    # 박스 좌표 추출\n",
    "                    xmin, ymin, xmax, ymax = box.int().tolist()\n",
    "                    \n",
    "                    # 영역 마스킹 (다양한 방법 중 하나 선택)\n",
    "                    # 1. 평균 색상으로 대체\n",
    "                    # mean_color = np.mean(img_np, axis=(0, 1))\n",
    "                    # img_np[ymin:ymax, xmin:xmax] = mean_color\n",
    "                    \n",
    "                    # 2. 가우시안 블러 적용\n",
    "                    roi = img_np[ymin:ymax, xmin:xmax]\n",
    "                    if roi.size > 0:  # 유효한 영역인 경우\n",
    "                        blurred = cv2.GaussianBlur(roi, (51, 51), 0)\n",
    "                        img_np[ymin:ymax, xmin:xmax] = blurred\n",
    "            \n",
    "            # 이미지로 변환하여 반환\n",
    "            masked_image = Image.fromarray(img_np)\n",
    "            return masked_image\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"사람 마스킹 중 오류 발생: {e}\")\n",
    "            return image  # 오류 시 원본 이미지 반환\n",
    "\n",
    "def extract_datetime(image_path):\n",
    "    \"\"\"이미지의 EXIF 데이터에서 촬영 시간 추출\"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        exif_data = img._getexif()\n",
    "        if exif_data:\n",
    "            for tag_id, value in exif_data.items():\n",
    "                tag = TAGS.get(tag_id, tag_id)\n",
    "                if tag == 'DateTimeOriginal':\n",
    "                    return datetime.strptime(value, '%Y:%m:%d %H:%M:%S')\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting datetime from {image_path}: {e}\")\n",
    "    return None\n",
    "\n",
    "def create_people_detector():\n",
    "    \"\"\"사람 감지 모델 초기화\"\"\"\n",
    "    try:\n",
    "        print(\"사람 감지 모델 로딩 중...\")\n",
    "        processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\", use_fast=True)\n",
    "        model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "        \n",
    "        # 감지 모델을 GPU로 이동 (가능한 경우)\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # 사용자 정의 감지기 클래스 생성\n",
    "        class PeopleDetector:\n",
    "            def __init__(self, processor, model):\n",
    "                self.processor = processor\n",
    "                self.model = model\n",
    "                self.device = device\n",
    "            \n",
    "            def __call__(self, images, return_tensors=\"pt\"):\n",
    "                inputs = self.processor(images=images, return_tensors=return_tensors)\n",
    "                # 입력을 디바이스로 이동\n",
    "                inputs = {k: v.to(self.device) if isinstance(v, torch.Tensor) else v \n",
    "                          for k, v in inputs.items()}\n",
    "                return inputs\n",
    "            \n",
    "            def post_process_object_detection(self, outputs, **kwargs):\n",
    "                return self.processor.post_process_object_detection(outputs, **kwargs)\n",
    "        \n",
    "        return PeopleDetector(processor, model)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"사람 감지 모델 로드 실패: {e}\")\n",
    "        print(\"사람 마스킹 비활성화 중...\")\n",
    "        return None\n",
    "\n",
    "def extract_features_with_dinov2(image_paths, batch_size=8, remove_people=True):\n",
    "    \"\"\"DINOv2-giant 모델을 사용하여 이미지 특징 추출 (사람 마스킹 옵션 포함)\"\"\"\n",
    "    print(\"DINOv2-giant 모델 로딩 중...\")\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"사용 중인 디바이스: {device}\")\n",
    "    \n",
    "    # 사람 감지 모델 초기화 (사람 제거 옵션이 활성화된 경우)\n",
    "    people_detector = create_people_detector() if remove_people else None\n",
    "    \n",
    "    try:\n",
    "        # DINOv2 모델 및 프로세서 로드\n",
    "        processor = AutoImageProcessor.from_pretrained(\"facebook/dinov2-giant\", use_fast=True)\n",
    "        model = AutoModel.from_pretrained(\"facebook/dinov2-giant\")\n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # 이미지 전처리 변환\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((518, 518)),  # DINOv2 권장 사이즈\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        \n",
    "        # 데이터셋 및 데이터로더 생성 (사람 마스킹 옵션 포함)\n",
    "        dataset = ImageDataset(\n",
    "            image_paths, \n",
    "            transform=transform, \n",
    "            remove_people=remove_people, \n",
    "            people_detector=people_detector\n",
    "        )\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "        \n",
    "        features = []\n",
    "        valid_paths = []\n",
    "        datetime_list = []\n",
    "        \n",
    "        print(\"이미지 특징 추출 중...\")\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm.tqdm(dataloader, desc=\"특징 추출\"):\n",
    "                images = batch['image'].to(device)\n",
    "                paths = batch['path']\n",
    "                errors = batch.get('error', [False] * len(paths))\n",
    "                \n",
    "                # 유효한 이미지만 처리\n",
    "                valid_indices = [i for i, error in enumerate(errors) if not error]\n",
    "                \n",
    "                if valid_indices:\n",
    "                    # DINOv2 모델로 특징 추출\n",
    "                    outputs = model(images[valid_indices])\n",
    "                    # [CLS] 토큰의 특징 벡터 사용\n",
    "                    batch_features = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "                    \n",
    "                    for i, idx in enumerate(valid_indices):\n",
    "                        features.append(batch_features[i])\n",
    "                        valid_paths.append(paths[idx])\n",
    "                        \n",
    "                        # 시간 정보 추출\n",
    "                        dt = extract_datetime(paths[idx])\n",
    "                        datetime_list.append(dt)\n",
    "        \n",
    "        print(f\"총 {len(valid_paths)}개 이미지에서 특징 추출 완료\")\n",
    "        return features, valid_paths, datetime_list\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"DINOv2 모델 사용 중 오류 발생: {e}\")\n",
    "        # 오류 시 기본 특징 추출 방식으로 대체\n",
    "        print(\"기본 특징 추출 방식으로 대체합니다...\")\n",
    "        return extract_features_with_opencv(image_paths, remove_people, people_detector)\n",
    "\n",
    "def extract_features_with_opencv(image_paths, remove_people=True, people_detector=None):\n",
    "    \"\"\"OpenCV를 사용한 백업 특징 추출 방식 (사람 마스킹 옵션 포함)\"\"\"\n",
    "    print(\"OpenCV를 사용하여 특징 추출 중...\")\n",
    "    features_list = []\n",
    "    valid_paths = []\n",
    "    datetime_list = []\n",
    "    \n",
    "    for i, path in enumerate(image_paths):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"  {i}/{len(image_paths)} 처리 중...\")\n",
    "        \n",
    "        try:\n",
    "            # 이미지 로딩 (PIL로 로드하여 필요시 사람 마스킹 적용)\n",
    "            if remove_people and people_detector is not None:\n",
    "                pil_img = Image.open(path).convert('RGB')\n",
    "                pil_img = ImageDataset.mask_people(pil_img, people_detector)\n",
    "                img = np.array(pil_img)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)  # PIL은 RGB, OpenCV는 BGR\n",
    "            else:\n",
    "                # 일반적인 OpenCV 로딩\n",
    "                img = cv2.imread(path)\n",
    "            \n",
    "            if img is None:\n",
    "                continue\n",
    "            \n",
    "            # 이미지 크기 조정\n",
    "            img = cv2.resize(img, (224, 224))\n",
    "            \n",
    "            # 색상 히스토그램 특징 추출\n",
    "            hist_features = []\n",
    "            for i in range(3):  # BGR 채널\n",
    "                hist = cv2.calcHist([img], [i], None, [64], [0, 256])\n",
    "                hist = cv2.normalize(hist, hist).flatten()\n",
    "                hist_features.extend(hist)\n",
    "            \n",
    "            # 간단한 전역 특징 추가\n",
    "            for i in range(3):\n",
    "                hist_features.append(float(np.mean(img[:,:,i])))\n",
    "                hist_features.append(float(np.std(img[:,:,i])))\n",
    "            \n",
    "            features = np.array(hist_features, dtype=float)\n",
    "            \n",
    "            # 특징 벡터가 유효한지 확인\n",
    "            if not np.all(np.isfinite(features)):\n",
    "                continue\n",
    "                \n",
    "            features_list.append(features)\n",
    "            valid_paths.append(path)\n",
    "            \n",
    "            # 시간 정보 추출\n",
    "            dt = extract_datetime(path)\n",
    "            datetime_list.append(dt)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {path}: {e}\")\n",
    "    \n",
    "    return features_list, valid_paths, datetime_list\n",
    "\n",
    "def cluster_images(features, valid_paths, datetime_list, n_clusters=None):\n",
    "    \"\"\"이미지 클러스터링\"\"\"\n",
    "    if not features or not valid_paths:\n",
    "        print(\"유효한 특징이 추출되지 않았습니다.\")\n",
    "        return None, None\n",
    "    \n",
    "    # 특징 데이터 정규화\n",
    "    print(\"특징 데이터 정규화 중...\")\n",
    "    X = np.array(features)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_combined = X_scaled\n",
    "    \n",
    "    # 시간 특징 추가 (있는 경우)\n",
    "    # has_time_data = all(dt is not None for dt in datetime_list)\n",
    "    # if has_time_data:\n",
    "    #     print(\"시간 정보를 활용하여 클러스터링합니다...\")\n",
    "    #     # 시간을 타임스탬프로 변환하고 정규화\n",
    "    #     timestamps = np.array([(dt - datetime(1970, 1, 1)).total_seconds() for dt in datetime_list]).reshape(-1, 1)\n",
    "    #     time_scaler = StandardScaler()\n",
    "    #     timestamps_scaled = time_scaler.fit_transform(timestamps)\n",
    "        \n",
    "    #     # 가중치 적용 (시간 정보에 가중치 부여)\n",
    "    #     time_weight = 0.3\n",
    "    #     feature_weight = 1.0 - time_weight\n",
    "        \n",
    "    #     # 특징과 시간 정보 결합\n",
    "    #     X_combined = np.hstack([X_scaled * feature_weight, timestamps_scaled * time_weight])\n",
    "    # else:\n",
    "    #     print(\"시간 정보가 없어 이미지 특징만으로 클러스터링합니다...\")\n",
    "    #     X_combined = X_scaled\n",
    "    \n",
    "    # 클러스터링 알고리즘 선택 및 적용\n",
    "    print(\"클러스터링 중...\")\n",
    "    if n_clusters and n_clusters > 0:\n",
    "        print(f\"K-means 클러스터링으로 {n_clusters}개 구역으로 분류합니다.\")\n",
    "        # K-means 클러스터링 \n",
    "        clusterer = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    else:\n",
    "        print(\"DBSCAN 클러스터링으로 자동 구역 분류를 수행합니다.\")\n",
    "        # DBSCAN 클러스터링 (클러스터 수를 자동으로 결정)\n",
    "        eps = 0.5  # 밀도 기반 클러스터링의 이웃 거리 임계값\n",
    "        min_samples = 5  # 핵심 포인트 기준 최소 샘플 수\n",
    "        clusterer = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    \n",
    "    labels = clusterer.fit_predict(X_combined)\n",
    "    \n",
    "    return valid_paths, labels\n",
    "\n",
    "def organize_images_by_cluster(image_paths, labels, output_dir):\n",
    "    \"\"\"클러스터링 결과에 따라 이미지 정리\"\"\"\n",
    "    # 클러스터별 디렉토리 생성\n",
    "    unique_labels = set(labels)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        # -1은 DBSCAN에서 노이즈를 나타냄\n",
    "        if label == -1:\n",
    "            cluster_dir = os.path.join(output_dir, \"uncategorized\")\n",
    "        else:\n",
    "            cluster_dir = os.path.join(output_dir, f\"zone_{label+1}\")\n",
    "        \n",
    "        os.makedirs(cluster_dir, exist_ok=True)\n",
    "    \n",
    "    # 각 이미지를 해당 클러스터 디렉토리로 복사\n",
    "    print(\"이미지를 구역별 폴더로 복사하는 중...\")\n",
    "    for path, label in zip(image_paths, labels):\n",
    "        if label == -1:\n",
    "            dest_dir = os.path.join(output_dir, \"uncategorized\")\n",
    "        else:\n",
    "            dest_dir = os.path.join(output_dir, f\"zone_{label+1}\")\n",
    "        \n",
    "        # 원본 파일명 유지하면서 복사\n",
    "        filename = os.path.basename(path)\n",
    "        shutil.copy2(path, os.path.join(dest_dir, filename))\n",
    "    \n",
    "    # 각 클러스터에 몇 개의 이미지가 있는지 출력\n",
    "    print(\"\\n분류 결과:\")\n",
    "    for label in unique_labels:\n",
    "        if label == -1:\n",
    "            dir_name = \"uncategorized\"\n",
    "        else:\n",
    "            dir_name = f\"zone_{label+1}\"\n",
    "        \n",
    "        cluster_dir = os.path.join(output_dir, dir_name)\n",
    "        num_images = len(os.listdir(cluster_dir))\n",
    "        print(f\"{dir_name}: {num_images}개 이미지\")\n",
    "\n",
    "def visualize_clusters(image_paths, labels, output_dir):\n",
    "    \"\"\"클러스터링 결과 시각화\"\"\"\n",
    "    # 각 클러스터에서 3개의 샘플 이미지를 보여줌\n",
    "    unique_labels = sorted(set(labels))\n",
    "    if -1 in unique_labels:  # uncategorized를 마지막에 표시\n",
    "        unique_labels.remove(-1)\n",
    "        unique_labels.append(-1)\n",
    "    \n",
    "    # 시각화를 위한 그리드 설정\n",
    "    n_clusters = len(unique_labels)\n",
    "    \n",
    "    # 클러스터가 없으면 시각화를 건너뜁니다\n",
    "    if n_clusters == 0:\n",
    "        print(\"시각화할 클러스터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 각 클러스터마다 최대 3개의 이미지를 표시\n",
    "    max_samples = 3\n",
    "    fig, axes = plt.subplots(n_clusters, max_samples, figsize=(15, 5 * n_clusters))\n",
    "    \n",
    "    # 단일 클러스터이거나 단일 샘플인 경우 축 처리\n",
    "    if n_clusters == 1:\n",
    "        axes = np.array([axes])  # 2D 배열로 만들기\n",
    "    \n",
    "    print(\"클러스터 시각화 생성 중...\")\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        # 해당 클러스터의 이미지 경로 가져오기\n",
    "        cluster_images = [path for path, lbl in zip(image_paths, labels) if lbl == label]\n",
    "        \n",
    "        # 최대 3개의 샘플 선택\n",
    "        samples = cluster_images[:max_samples]\n",
    "        \n",
    "        # 샘플 이미지 표시\n",
    "        for j in range(max_samples):\n",
    "            ax = axes[i, j] if n_clusters > 1 else axes[j]\n",
    "            \n",
    "            if j < len(samples):  # 샘플이 있는 경우\n",
    "                try:\n",
    "                    sample = samples[j]\n",
    "                    img = cv2.imread(sample)\n",
    "                    if img is not None:\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # OpenCV는 BGR, matplotlib은 RGB\n",
    "                        ax.imshow(img)\n",
    "                        ax.set_title(f\"Cluster {label+1 if label != -1 else 'Uncategorized'}\\nSample {j+1}\")\n",
    "                    else:\n",
    "                        ax.text(0.5, 0.5, \"이미지 로드 실패\", ha='center', va='center')\n",
    "                except Exception as e:\n",
    "                    print(f\"Error displaying sample {samples[j] if j < len(samples) else 'unknown'}: {e}\")\n",
    "                    ax.text(0.5, 0.5, \"이미지 표시 오류\", ha='center', va='center')\n",
    "            else:  # 샘플이 부족한 경우\n",
    "                ax.text(0.5, 0.5, \"샘플 없음\", ha='center', va='center')\n",
    "            \n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    try:\n",
    "        vis_path = os.path.join(output_dir, \"cluster_samples.png\")\n",
    "        plt.savefig(vis_path)\n",
    "        plt.close()\n",
    "        print(f\"클러스터 시각화가 {vis_path}에 저장되었습니다.\")\n",
    "    except Exception as e:\n",
    "        print(f\"시각화 저장 중 오류 발생: {e}\")\n",
    "        plt.close()\n",
    "\n",
    "def save_processed_examples(original_paths, output_dir, people_detector, count=5):\n",
    "    \"\"\"사람이 마스킹된 이미지 예시 저장\"\"\"\n",
    "    if people_detector is None:\n",
    "        return\n",
    "    \n",
    "    print(\"사람 마스킹 처리 예시 생성 중...\")\n",
    "    example_dir = os.path.join(output_dir, \"people_masking_examples\")\n",
    "    os.makedirs(example_dir, exist_ok=True)\n",
    "    \n",
    "    # 무작위로 몇 개의 이미지 선택\n",
    "    import random\n",
    "    sample_paths = random.sample(original_paths, min(count, len(original_paths)))\n",
    "    \n",
    "    for i, path in enumerate(sample_paths):\n",
    "        try:\n",
    "            # 원본 이미지 로드\n",
    "            original_img = Image.open(path).convert('RGB')\n",
    "            \n",
    "            # 사람 마스킹 적용\n",
    "            masked_img = ImageDataset.mask_people(ImageDataset(), original_img, people_detector)\n",
    "            \n",
    "            # 원본과 마스킹된 이미지 나란히 저장\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "            \n",
    "            # 원본 이미지\n",
    "            axes[0].imshow(np.array(original_img))\n",
    "            axes[0].set_title(\"원본 이미지\")\n",
    "            axes[0].axis('off')\n",
    "            \n",
    "            # 마스킹된 이미지\n",
    "            axes[1].imshow(np.array(masked_img))\n",
    "            axes[1].set_title(\"사람 마스킹 처리된 이미지\")\n",
    "            axes[1].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            example_path = os.path.join(example_dir, f\"example_{i+1}.png\")\n",
    "            plt.savefig(example_path)\n",
    "            plt.close()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"예시 이미지 생성 중 오류: {e}\")\n",
    "    \n",
    "    print(f\"사람 마스킹 처리 예시가 {example_dir}에 저장되었습니다.\")\n",
    "\n",
    "def main():\n",
    "    print(\"=\"*50)\n",
    "    print(\"잔디 깎기 작업 사진 구역별 분류 프로그램 (사람 특징 무시 버전)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # 디렉토리 설정 확인\n",
    "    print(f\"입력 디렉토리: {IMAGE_DIR}\")\n",
    "    print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
    "    \n",
    "    # 출력 디렉토리 생성\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "    \n",
    "    # 지원하는 이미지 확장자\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
    "    \n",
    "    # 모든 이미지 파일 경로 수집\n",
    "    print(\"이미지 파일 검색 중...\")\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(IMAGE_DIR):\n",
    "        for file in files:\n",
    "            ext = os.path.splitext(file)[1].lower()\n",
    "            if ext in valid_extensions:\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    print(f\"총 {len(image_paths)}개의 이미지를 발견했습니다.\")\n",
    "    \n",
    "    # 구역 수 입력 (자동 결정을 원하면 0 입력)\n",
    "    try:\n",
    "        n_zones = int(input(\"구역 수를 입력하세요 (자동 결정은 0 입력): \"))\n",
    "    except ValueError:\n",
    "        print(\"유효하지 않은 입력입니다. 자동으로 구역을 결정합니다.\")\n",
    "        n_zones = 0\n",
    "    \n",
    "    # 사람 특징을 무시하는 옵션 활성화\n",
    "    remove_people = True\n",
    "    print(f\"사람 특징 무시 옵션: {'활성화' if remove_people else '비활성화'}\")\n",
    "    \n",
    "    try:\n",
    "        # 특징 추출\n",
    "        features, valid_paths, datetime_list = extract_features_with_dinov2(\n",
    "            image_paths, \n",
    "            remove_people=remove_people\n",
    "        )\n",
    "        \n",
    "        # 클러스터링\n",
    "        valid_paths, labels = cluster_images(\n",
    "            features, \n",
    "            valid_paths, \n",
    "            datetime_list, \n",
    "            n_clusters=n_zones if n_zones > 0 else None\n",
    "        )\n",
    "        \n",
    "        if valid_paths is None or labels is None:\n",
    "            print(\"클러스터링에 실패했습니다.\")\n",
    "            return\n",
    "        \n",
    "        # 클러스터링 결과에 따라 이미지 정리\n",
    "        organize_images_by_cluster(valid_paths, labels, OUTPUT_DIR)\n",
    "        \n",
    "        # 클러스터 시각화\n",
    "        visualize_clusters(valid_paths, labels, OUTPUT_DIR)\n",
    "        \n",
    "        # 마스킹 예시 생성 (선택적)\n",
    "        if remove_people:\n",
    "            people_detector = create_people_detector()\n",
    "            if people_detector:\n",
    "                save_processed_examples(image_paths[:10], OUTPUT_DIR, people_detector)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"처리 중 오류 발생: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\"+\"=\"*50)\n",
    "    print(f\"이미지 분류가 완료되었습니다.\")\n",
    "    print(f\"결과는 {OUTPUT_DIR} 디렉토리에 저장되었습니다.\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "잔디 깎기 작업 사진 구역별 분류 프로그램 (DINOv2 버전)\n",
      "입력 디렉토리: ./1차\n",
      "출력 디렉토리: ./1차_claude2\n",
      "이미지 파일 검색 중...\n",
      "총 232개의 이미지를 발견했습니다.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"잔디 깎기 작업 사진 구역별 분류 프로그램 (DINOv2 버전)\")\n",
    "\n",
    "# 고정된 입력 및 출력 디렉토리 설정\n",
    "IMAGE_DIR = \"./1차\"\n",
    "OUTPUT_DIR = IMAGE_DIR + \"_claude2\"\n",
    "\n",
    "\n",
    "# 디렉토리 설정 확인\n",
    "print(f\"입력 디렉토리: {IMAGE_DIR}\")\n",
    "print(f\"출력 디렉토리: {OUTPUT_DIR}\")\n",
    "\n",
    "# 출력 디렉토리 생성\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# 지원하는 이미지 확장자\n",
    "valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.gif'}\n",
    "\n",
    "# 모든 이미지 파일 경로 수집\n",
    "print(\"이미지 파일 검색 중...\")\n",
    "image_paths = []\n",
    "for root, _, files in os.walk(IMAGE_DIR):\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[1].lower()\n",
    "        if ext in valid_extensions:\n",
    "            image_paths.append(os.path.join(root, file))\n",
    "\n",
    "print(f\"총 {len(image_paths)}개의 이미지를 발견했습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "사람 특징 무시 옵션: 비활성화\n",
      "DINOv2-giant 모델 로딩 중...\n",
      "사용 중인 디바이스: cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_fast` is set to `True` but the image processor class does not have a fast version.  Falling back to the slow version.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 특징 추출 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "특징 추출: 100%|██████████| 29/29 [14:29<00:00, 29.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 232개 이미지에서 특징 추출 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remove_people = False\n",
    "print(f\"사람 특징 무시 옵션: {'활성화' if remove_people else '비활성화'}\")\n",
    "\n",
    "# DINOv2 모델을 사용하여 이미지 특징 추출\n",
    "features, valid_paths, datetime_list = extract_features_with_dinov2(\n",
    "    image_paths, \n",
    "    remove_people=remove_people\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특징 데이터 정규화 중...\n",
      "클러스터링 중...\n",
      "K-means 클러스터링으로 55개 구역으로 분류합니다.\n",
      "이미지를 구역별 폴더로 복사하는 중...\n",
      "\n",
      "분류 결과:\n",
      "zone_1: 2개 이미지\n",
      "zone_2: 6개 이미지\n",
      "zone_3: 12개 이미지\n",
      "zone_4: 5개 이미지\n",
      "zone_5: 5개 이미지\n",
      "zone_6: 12개 이미지\n",
      "zone_7: 7개 이미지\n",
      "zone_8: 6개 이미지\n",
      "zone_9: 6개 이미지\n",
      "zone_10: 5개 이미지\n",
      "zone_11: 6개 이미지\n",
      "zone_12: 6개 이미지\n",
      "zone_13: 3개 이미지\n",
      "zone_14: 4개 이미지\n",
      "zone_15: 2개 이미지\n",
      "zone_16: 3개 이미지\n",
      "zone_17: 4개 이미지\n",
      "zone_18: 5개 이미지\n",
      "zone_19: 7개 이미지\n",
      "zone_20: 5개 이미지\n",
      "zone_21: 3개 이미지\n",
      "zone_22: 3개 이미지\n",
      "zone_23: 3개 이미지\n",
      "zone_24: 4개 이미지\n",
      "zone_25: 3개 이미지\n",
      "zone_26: 3개 이미지\n",
      "zone_27: 4개 이미지\n",
      "zone_28: 3개 이미지\n",
      "zone_29: 6개 이미지\n",
      "zone_30: 2개 이미지\n",
      "zone_31: 2개 이미지\n",
      "zone_32: 2개 이미지\n",
      "zone_33: 2개 이미지\n",
      "zone_34: 7개 이미지\n",
      "zone_35: 5개 이미지\n",
      "zone_36: 5개 이미지\n",
      "zone_37: 5개 이미지\n",
      "zone_38: 2개 이미지\n",
      "zone_39: 2개 이미지\n",
      "zone_40: 5개 이미지\n",
      "zone_41: 4개 이미지\n",
      "zone_42: 8개 이미지\n",
      "zone_43: 7개 이미지\n",
      "zone_44: 2개 이미지\n",
      "zone_45: 3개 이미지\n",
      "zone_46: 4개 이미지\n",
      "zone_47: 1개 이미지\n",
      "zone_48: 2개 이미지\n",
      "zone_49: 2개 이미지\n",
      "zone_50: 3개 이미지\n",
      "zone_51: 3개 이미지\n",
      "zone_52: 6개 이미지\n",
      "zone_53: 2개 이미지\n",
      "zone_54: 1개 이미지\n",
      "zone_55: 2개 이미지\n"
     ]
    }
   ],
   "source": [
    "# 클러스터링\n",
    "n_zones = 55\n",
    "valid_paths, labels = cluster_images(\n",
    "    features, \n",
    "    valid_paths, \n",
    "    datetime_list, \n",
    "    n_clusters=n_zones if n_zones > 0 else None\n",
    ")\n",
    "organize_images_by_cluster(valid_paths, labels, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클러스터 시각화 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:427: UserWarning: Glyph 49368 (\\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:427: UserWarning: Glyph 54540 (\\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:427: UserWarning: Glyph 50630 (\\N{HANGUL SYLLABLE EOBS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:427: UserWarning: Glyph 51020 (\\N{HANGUL SYLLABLE EUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:430: UserWarning: Glyph 49368 (\\N{HANGUL SYLLABLE SAEM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(vis_path)\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:430: UserWarning: Glyph 54540 (\\N{HANGUL SYLLABLE PEUL}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(vis_path)\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:430: UserWarning: Glyph 50630 (\\N{HANGUL SYLLABLE EOBS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(vis_path)\n",
      "/var/folders/fv/fgltl3gj7gzf7yxy510rkjv00000gn/T/ipykernel_14645/141794884.py:430: UserWarning: Glyph 51020 (\\N{HANGUL SYLLABLE EUM}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(vis_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클러스터 시각화가 ./1차_claude2/cluster_samples.png에 저장되었습니다.\n",
      "이미지 분류가 완료되었습니다.\n",
      "결과는 ./1차_claude2 디렉토리에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "# 클러스터 시각화\n",
    "visualize_clusters(valid_paths, labels, OUTPUT_DIR)\n",
    "\n",
    "if remove_people:\n",
    "    people_detector = create_people_detector()c\n",
    "    if people_detector:\n",
    "        save_processed_examples(image_paths[:10], OUTPUT_DIR, people_detector)\n",
    "        \n",
    "print(f\"이미지 분류가 완료되었습니다.\")\n",
    "print(f\"결과는 {OUTPUT_DIR} 디렉토리에 저장되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
